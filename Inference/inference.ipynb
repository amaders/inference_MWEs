{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae4cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import requests\n",
    "from IPython.display import Image, display\n",
    "import time\n",
    "import openai\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "notion_api_key = os.getenv(\"NOTION_API_KEY\")\n",
    "google_calendar_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "openai.api_key = openai_api_key\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed840584",
   "metadata": {},
   "source": [
    "# **Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a1914",
   "metadata": {},
   "source": [
    "If we were to progress through the topics of this course chronologically, this section would be towards the very end; inference is the function that connects the engineering and scientific heavy lifting of training to deployment, and it functionally looks more similar to traditional back-end engineering than pure machine learning. \n",
    "\n",
    "However, inference is a good place to begin because it defines the goal to which we will spend the rest of the semester working towards and demonstrates the capabilities of models that we will work to better understand. It also is the layer in which a lot of value will accrue in the coming years, and I hope to demonstrate that while it is technically more straightforward, there is a lot of juice to squeeze in this area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3141187c",
   "metadata": {},
   "source": [
    "**What is Inference?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180ffc6",
   "metadata": {},
   "source": [
    "Inference is the process of using a trained model to generate outputs. Today, inference can be done by downloading pre-trained models and using GPUs to run them, or by paying a provider to offload the computational and operational burden and submitting inference requests via APIs. These are often called model providers. \n",
    "\n",
    "The most straightward way to run \"inference\" is simply by using one of these model providers via API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412fae2",
   "metadata": {},
   "source": [
    "**OpenRouter**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88929d6c",
   "metadata": {},
   "source": [
    "OpenRouter unifies many model providers into one API service, allowing users to toggle between different models and providers to optimize for cost, availability, speed, etc. It's important to note the differences between a model and a provider. A model is the actual set of parameters than constitute the LLM and which we use to generate outputs. A provider is an entity that provides the compute to run these models. \n",
    "\n",
    "In some cases where the models are proprietary (e.g. Anthopic and OpenAI) the owner of the model is by definition the only available provider, as they do not share their weights with any other organizations. For open-source models, however, there are often multiple providers competing for business.\n",
    "\n",
    "OpenRouter publicizes which models are their most popular, which gives us some intuition into the tradeoffs that people optimize for when choosing model providers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d2700",
   "metadata": {},
   "source": [
    "From the variation in popular models on OpenRouter, we can infer that there isn't one singular \"winner.\" Instead, different models have different strengths and weaknesses, and people find different models superior for their specific implementations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6464231d",
   "metadata": {},
   "source": [
    "![caption](images/figure1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de919dc",
   "metadata": {},
   "source": [
    "Let's examine some popular models. Openrouter gives us details on the pricing, modalities, settings, and more for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5789613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popular OpenRouter Models:\n",
      "\n",
      "Model: xAI: Grok Code Fast 1\n",
      "Modalities: text->text\n",
      "Supported Parameters: ['include_reasoning', 'logprobs', 'max_tokens', 'reasoning', 'response_format', 'seed', 'stop', 'structured_outputs', 'temperature', 'tool_choice', 'tools', 'top_logprobs', 'top_p']\n",
      "Context Length: 256,000 tokens\n",
      "Pricing: $0.200/1M input, $1.500/1M output\n",
      "--------------------------------------------------\n",
      "Model: Anthropic: Claude Sonnet 4\n",
      "Modalities: text+image->text\n",
      "Supported Parameters: ['include_reasoning', 'max_tokens', 'reasoning', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']\n",
      "Context Length: 1,000,000 tokens\n",
      "Pricing: $3.000/1M input, $15.000/1M output\n",
      "--------------------------------------------------\n",
      "Model: Google: Gemini 2.5 Flash Image Preview\n",
      "Modalities: text+image->text+image\n",
      "Supported Parameters: ['max_tokens', 'response_format', 'seed', 'structured_outputs', 'temperature', 'top_p']\n",
      "Context Length: 32,768 tokens\n",
      "Pricing: $0.300/1M input, $2.500/1M output\n",
      "--------------------------------------------------\n",
      "Model: DeepSeek: DeepSeek V3.1 (free)\n",
      "Modalities: text->text\n",
      "Supported Parameters: ['frequency_penalty', 'include_reasoning', 'max_tokens', 'min_p', 'presence_penalty', 'reasoning', 'repetition_penalty', 'response_format', 'seed', 'stop', 'temperature', 'tool_choice', 'tools', 'top_k', 'top_p']\n",
      "Context Length: 163,840 tokens\n",
      "Pricing: $0.000/1M input, $0.000/1M output\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Download a few schemas of popular OpenRouter models and display relevant information\n",
    "response = requests.get(\"https://openrouter.ai/api/v1/models\")\n",
    "models_data = response.json()\n",
    "\n",
    "popular_models = [\"x-ai/grok-code-fast-1\", \"anthropic/claude-sonnet-4\", \"google/gemini-2.5-flash-image-preview\", \"deepseek/deepseek-chat-v3.1:free\"]\n",
    "\n",
    "print(\"Popular OpenRouter Models:\\n\")\n",
    "for model_id in popular_models:\n",
    "    for model in models_data.get(\"data\", []):\n",
    "        if model.get(\"id\") == model_id:\n",
    "            print(f\"Model: {model['name']}\")\n",
    "            print(f\"Modalities: {model['architecture']['modality']}\")\n",
    "            print(f\"Supported Parameters: {model['supported_parameters']}\")\n",
    "            print(f\"Context Length: {model['context_length']:,} tokens\")\n",
    "            pricing = model['pricing']\n",
    "            print(f\"Pricing: ${float(pricing['prompt'])*1000000:.3f}/1M input, ${float(pricing['completion'])*1000000:.3f}/1M output\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6184f8",
   "metadata": {},
   "source": [
    "Note the differences here. \n",
    "\n",
    "First, see that DeepSeek 3.1 is being offered for free versus Sonnet 4's $15/million output tokens, despite the two models scoring closely on SWE-Bench, 72.7% vs. 66% (https://www.anthropic.com/news/claude-4, https://api-docs.deepseek.com/news/news250821). Still, both have high usage volume; some applications have found use cases for DeepSeek's extremely cheap inference, while others have found the marginal cost of intelligence to be worth paying for accesss to Sonnet.\n",
    "\n",
    "We also see that the modalities and parameters of each model look very different. Some are text->text while others are multimodal, and  inference parameters like reasoning effort, temperature, and tool calls differ between models. It is worth exploring how these different setups could integrate into your specific use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc79a2",
   "metadata": {},
   "source": [
    "Let's demonstrate on GPT-5, OpenAI's newest model, which provides great intellegence per unit cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02c1798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code dreams in silence,\n",
      "learning the shape of our words—\n",
      "mind born of mirrors.\n"
     ]
    }
   ],
   "source": [
    "# Use gpt-5 from OpenRouter to complete a vanilla completion task\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {openrouter_api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"openai/gpt-5\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku about artificial intelligence\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response_text = requests.post(\n",
    "    \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "    headers=headers,\n",
    "    json=data\n",
    ")\n",
    "\n",
    "print(response_text.json()['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f8ae4",
   "metadata": {},
   "source": [
    "Many models have different input/output modalities available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3cf8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\"\n",
    "display(Image(url=cat_image_url, width=300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c65dca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Appearance: A ginger/orange tabby domestic shorthair with a soft, dense coat. The fur shows classic tabby striping—fine, warm orange stripes over a lighter, creamy base. There’s a clear “M” marking on the forehead and paler fur around the muzzle, chin, and chest.\n",
      "- Face and features: Round face with full cheeks and pronounced whisker pads. Long white whiskers and a few white eyebrow whiskers. Nose leather is pink with a slightly darker outline. Ears are medium-sized, triangular, and upright with light inner fur.\n",
      "- Eyes: Large, almond-shaped, golden-amber eyes with vertical pupils; an attentive, gentle expression.\n",
      "- Build and posture: Appears to be an adult cat of healthy weight. The photo shows the head, shoulders, and upper body; the cat is facing the camera with a slight, curious head tilt.\n",
      "- Setting: Shot in natural light with a softly blurred outdoor background; a red line (likely a hose or cable) runs diagonally behind the cat, making the warm coat color stand out.\n"
     ]
    }
   ],
   "source": [
    "# Use gpt-5 to complete a task using a photo of a cat as input and ask it to describe the cat\n",
    "\n",
    "data_vision = {\n",
    "    \"model\": \"openai/gpt-5\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Please describe this cat in detail.\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": cat_image_url}}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "response_vision = requests.post(\n",
    "    \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "    headers=headers,\n",
    "    json=data_vision\n",
    ")\n",
    "\n",
    "print(response_vision.json()['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b353c4",
   "metadata": {},
   "source": [
    "**Determining costs is an important part of inference.**\n",
    "\n",
    "Inference costs are broken down into a few components:\n",
    "- price per input token\n",
    "- price per output token\n",
    "- additional tool fees\n",
    "\n",
    "New models utilize \"reasoning\" capabilities, which is when a model engages in a self-reflective dialogue to reason through a problem. This uses additional tokens that are often billed as additional output tokens, even though you do not observe them in the output. Openrouter automatically adds them to the output token count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199d9b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Breakdown for GPT-5 Calls:\n",
      "--------------------------------------------------\n",
      "Text Completion Task:\n",
      "  Input tokens: 13\n",
      "  Output tokens: 855\n",
      "  Cost: $0.004283\n",
      "\n",
      "Vision Task (Cat Description):\n",
      "  Input tokens: 640\n",
      "  Output tokens: 675\n",
      "  Cost: $0.003775\n",
      "\n",
      "Total Cost: $0.008058\n"
     ]
    }
   ],
   "source": [
    "# Report the cost breakdown from the previous two GPT-5 calls\n",
    "\n",
    "# Get pricing for GPT-5\n",
    "for model in models_data.get(\"data\", []):\n",
    "    if model.get(\"id\") == \"openai/gpt-5\":\n",
    "        gpt5_pricing = model['pricing']\n",
    "        break\n",
    "\n",
    "# Calculate costs\n",
    "text_prompt_tokens = response_text.json()['usage']['prompt_tokens']\n",
    "text_completion_tokens = response_text.json()['usage']['completion_tokens']\n",
    "vision_prompt_tokens = response_vision.json()['usage']['prompt_tokens']\n",
    "vision_completion_tokens = response_vision.json()['usage']['completion_tokens']\n",
    "\n",
    "text_cost = (text_prompt_tokens * float(gpt5_pricing['prompt']) + \n",
    "             text_completion_tokens * float(gpt5_pricing['completion']))\n",
    "\n",
    "vision_cost = (vision_prompt_tokens * float(gpt5_pricing['prompt']) + \n",
    "               vision_completion_tokens * float(gpt5_pricing['completion']))\n",
    "\n",
    "print(\"Cost Breakdown for GPT-5 Calls:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Text Completion Task:\")\n",
    "print(f\"  Input tokens: {text_prompt_tokens}\")\n",
    "print(f\"  Output tokens: {text_completion_tokens}\")\n",
    "print(f\"  Cost: ${text_cost:.6f}\")\n",
    "print()\n",
    "print(f\"Vision Task (Cat Description):\")\n",
    "print(f\"  Input tokens: {vision_prompt_tokens}\")\n",
    "print(f\"  Output tokens: {vision_completion_tokens}\")\n",
    "print(f\"  Cost: ${vision_cost:.6f}\")\n",
    "print()\n",
    "print(f\"Total Cost: ${(text_cost + vision_cost):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6cc0d0",
   "metadata": {},
   "source": [
    "**Routing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7494a",
   "metadata": {},
   "source": [
    "OpenRouter let's us optimize for various objectives during inference, such as latency, price, and throughput. \n",
    "\n",
    "Given a model (or sequential ranking of models), OpenRouter searches across providers for the criteria we want. Note that model routing precedes provider routing, so it first fixes the model from the model list we provide, then finds a provider for that given model. This is helpful to maximize performance/costs as well as control for model downtime.\n",
    "\n",
    "We can also add parameters, such as no data collection, to filter out unwanted providers. Full docs found here (https://openrouter.ai/docs/quickstart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find best (cheapest) provider for fixed model\n",
    "response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json={\n",
    "    \n",
    "    'models': ['meta-llama/llama-3.3-70b-instruct', 'deepseek/deepseek-chat-v3.1'],\n",
    "    'messages': [\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': 'What is the meaning of life? Answer in 5 words.'\n",
    "      }\n",
    "    ],\n",
    "\n",
    "    #tell openrouter to sort by price, other options are \"throughput\" and \"latency\"\n",
    "    #also tell openrouter to deny data collection\n",
    "    'provider': {\n",
    "      'sort': 'price',\n",
    "      'data_collection': 'deny'\n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d7b42b",
   "metadata": {},
   "source": [
    "Flow:\n",
    "- For llama-3.3, OpenRouter will search providers that do not collect data for the best price, then route to that provider for inference.\n",
    "- If no providers are found, then it will repeat that process for DeepSeek 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0620f52",
   "metadata": {},
   "source": [
    "**Understanding the difficulty of your task and choosing the appropriate model and settings is important.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56818631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-5 (High Reasoning):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short answer: With the leak, the entropy of the universe increases. The slow (quasi‑static) piston motion by itself could be reversible and produce no entropy, but mass flow through a finite pressure difference is intrinsically irreversible and produces entropy.\n",
      "\n",
      "Justification via the fundamental relation:\n",
      "- For each side i = 1 (gas in the cylinder) and 2 (reservoir),\n",
      "  dU_i = T_i dS_i − P_i dV_i + μ_i dN_i,\n",
      "  so\n",
      "  dS_i = (1/T_i) dU_i + (P_i/T_i) dV_i − (μ_i/T_i) dN_i.\n",
      "- For the isolated “universe” made of the two subsystems (piston/walls are insulating and included), the constraints are\n",
      "  dU_1 + dU_2 = 0, dV_1 + dV_2 = 0, dN_1 + dN_2 = 0.\n",
      "- Summing the two dS_i gives\n",
      "  dS_univ = (1/T_1 − 1/T_2) dU_1 + (P_1/T_1 − P_2/T_2) dV_1 − (μ_1/T_1 − μ_2/T_2) dN_1.\n",
      "\n",
      "Interpretation for the process:\n",
      "- The piston moves quasi‑statically and can be made essentially reversible (frictionless), so it need not produce entropy; in that limit P_1 ≈ P_2, making the second term negligible as a source of entropy production.\n",
      "- The leak is the key: matter flows from the higher‑pressure side to the lower‑pressure reservoir, i.e., dN_1 < 0. For an ideal gas,\n",
      "  μ(T, P) = μ°(T) + RT ln P,\n",
      "  so at comparable temperatures μ_1 > μ_2 when P_1 > P_2. Hence\n",
      "  −(μ_1/T_1 − μ_2/T_2) dN_1 > 0.\n",
      "  In the common case T_1 ≈ T_2 = T, the entropy increase from transferring dn moles is\n",
      "  dS_univ = (μ_1 − μ_2) dn / T = R dn ln(P_1/P_2) > 0.\n",
      "\n",
      "Conclusion: The leak makes the overall process irreversible and increases the entropy of the universe. Without the leak (reversible adiabatic piston motion), ΔS_univ = 0; with the leak, ΔS_univ > 0.\n",
      "\n",
      "Time taken: 262.60s\n",
      "--------------------------------------------------\n",
      "GPT-5-nano:\n",
      "Short answer: the entropy of the universe increases (ΔS_univ > 0).\n",
      "\n",
      "Reasoning (using the fundamental thermodynamic relation)\n",
      "\n",
      "- Stage 1 (piston moves quasi‑statistically, walls insulating): The process is reversible and adiabatic. For the gas inside the cylinder, dQ = 0 and the reversible adiabatic path gives dS_gas = 0. Thus no entropy is produced during this stage.\n",
      "\n",
      "- Stage 2 (the piston develops a tiny leak and gas flows to a reservoir at lower pressure): This is an open-system process with mass transfer across the boundary. It is driven by a finite pressure difference P_gas − P_reservoir > 0, so the mass transfer is inherently irreversible. For the gas inside the cylinder (the system), the fundamental relation for a simple compressible system with variable N reads\n",
      "  dU_gas = T_g dS_gas − P_g dV_gas + μ_g dN_gas.\n",
      "  During the leak the boundary movement is small, so to first approximation dV_gas ≈ 0 and dN_gas < 0 (mass leaves). Rewriting for the entropy change of the gas inside gives\n",
      "  dS_gas = [dU_gas − μ_g dN_gas] / T_gas.\n",
      "  The gas that leaves carries away energy (approximately the enthalpy per particle h_gas), so dU_gas is negative, and −μ_gas dN_gas is positive (since dN_gas < 0). The net effect is dS_gas > 0 for the leaking amount (any finite irreversible flow across a finite ΔP produces entropy).\n",
      "\n",
      "  At the same time, the released gas enters the reservoir (large, effectively at fixed T_res and P_res). The reservoir gains energy dU_res ≈ h_gas dN_leaked and its entropy increases by\n",
      "  dS_res = dU_res / T_res ≈ (h_gas dN_leaked) / T_res.\n",
      "  Since dN_leaked > 0 (the amount of gas entering the reservoir) and T_res > 0, we have dS_res > 0.\n",
      "\n",
      "- Total entropy change of the universe for the leak, ΔS_univ = ΔS_gas + ΔS_res, is the sum of two positive (or nonnegative) contributions and is strictly positive for any finite amount of gas transferred across a finite pressure difference. In other words, the irreversible leakage increases the entropy of the universe.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "- The reversible, adiabatic piston motion by itself does not change the entropy. The subsequent tiny leak, because it is driven by a finite pressure difference and involves irreversible mass transfer into a reservoir at lower pressure, produces entropy. Therefore the entropy of the universe increases: ΔS_univ > 0.\n"
     ]
    }
   ],
   "source": [
    "# Give GPT-5 a difficult question that requires a lot of reasoning and demonstrate\n",
    "# that a worse model will not be able to solve it and lower reasoning cannot solve it either\n",
    "\n",
    "difficult_question = \"\"\"\n",
    "A cylinder with insulating walls contains an ideal gas. \n",
    "The piston moves very slowly so the process is quasi-static. \n",
    "Then the piston develops a tiny leak, releasing gas into a reservoir at lower pressure. \n",
    "Show whether entropy of the universe increases or not, and justify using the fundamental thermodynamic relation.\n",
    "\"\"\"\n",
    "\n",
    "# Test with GPT-5 (high reasoning)\n",
    "print(\"GPT-5 (High Reasoning):\")\n",
    "start_time = time.time()\n",
    "response_gpt5 = requests.post(\n",
    "    \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "    headers=headers,\n",
    "    json={\n",
    "        \"model\": \"openai/gpt-5\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": difficult_question}],\n",
    "        \"reasoning\": { \"effort\": \"high\" },\n",
    "        \"temperature\": 1.0\n",
    "    }\n",
    ")\n",
    "gpt5_high_reasoning_time = time.time() - start_time\n",
    "print(response_gpt5.json()['choices'][0]['message']['content'])\n",
    "print(f\"\\nTime taken: {gpt5_high_reasoning_time:.2f}s\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"-\" * 50)\n",
    "print(\"GPT-5-nano:\")\n",
    "response_gpt5_nano = requests.post(\n",
    "    \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "    headers=headers,\n",
    "    json={\n",
    "        \"model\": \"openai/gpt-5-nano\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": difficult_question}],\n",
    "        \"temperature\": 1.0\n",
    "    }\n",
    ")\n",
    "gpt5_nano_time = time.time() - start_time\n",
    "\n",
    "print(response_gpt5_nano.json()['choices'][0]['message']['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23cbb603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Comparison:\n",
      "============================================================\n",
      "Model                Time (s)        Cost ($)        Quality        \n",
      "------------------------------------------------------------\n",
      "GPT-5                262.60          0.066482        High           \n",
      "GPT-5 nano           104.02          0.064453        Lower          \n",
      "------------------------------------------------------------\n",
      "\n",
      "GPT-5 is 1.0x more expensive than GPT-5 nano\n",
      "GPT-5 took 2.5x longer than GPT-5 nano\n"
     ]
    }
   ],
   "source": [
    "# Show that the higher reasoning model was slower and more expensive (but more performant)\n",
    "\n",
    "# Get pricing for both models\n",
    "for model in models_data.get(\"data\", []):\n",
    "    if model.get(\"id\") == \"openai/gpt-5\":\n",
    "        gpt5_pricing = model['pricing']\n",
    "    elif model.get(\"id\") == \"openai/gpt-3.5-turbo\":\n",
    "        gpt35_pricing = model['pricing']\n",
    "\n",
    "# Calculate costs\n",
    "gpt5_tokens = response_gpt5.json()['usage']\n",
    "gpt5_nano_tokens = response_gpt5_nano.json()['usage']\n",
    "\n",
    "gpt5_cost = (gpt5_tokens['prompt_tokens'] * float(gpt5_pricing['prompt']) + \n",
    "             gpt5_tokens['completion_tokens'] * float(gpt5_pricing['completion'])) \n",
    "\n",
    "gpt5_nano_cost = (gpt5_nano_tokens['prompt_tokens'] * float(gpt5_pricing['prompt']) + \n",
    "              gpt5_nano_tokens['completion_tokens'] * float(gpt5_pricing['completion'])) \n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<20} {'Time (s)':<15} {'Cost ($)':<15} {'Quality':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'GPT-5':<20} {gpt5_high_reasoning_time:<15.2f} {gpt5_cost:<15.6f} {'High':<15}\")\n",
    "print(f\"{'GPT-5 nano':<20} {gpt5_nano_time:<15.2f} {gpt5_nano_cost:<15.6f} {'Lower':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nGPT-5 is {gpt5_cost/gpt5_nano_cost:.1f}x more expensive than GPT-5 nano\")\n",
    "print(f\"GPT-5 took {gpt5_high_reasoning_time/gpt5_nano_time:.1f}x longer than GPT-5 nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852542cc",
   "metadata": {},
   "source": [
    "In the above cells, we began exploring the common considerations that one encounters during inference. Questions about the economics of requests, modalities and performance of different models, and the quality vs. cost tradeoff inform how AI applications are built. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff8c800",
   "metadata": {},
   "source": [
    "# **How can we improve inference performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7258fe",
   "metadata": {},
   "source": [
    "# **Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374e180",
   "metadata": {},
   "source": [
    "A recent paradigm that has improved the usefulness of LLMs is **tools**. Tools are functions that are provided to the model to achieve a specific task. Just like calculators are tools for humans to do arithmatic, tools are capabilities that models can use as necessary. Web search, code execution, and messaging integrations are common examples.\n",
    "\n",
    "Tool-calling has a few motivations.\n",
    "\n",
    "The need for tools is apparent when wanting to integrate LLMs into everyday products. What if we want a model to look up the weather at a location today? Or, what if we wanted a model to search through my Notion documents? Models would only be able to achieve these tasks provided they are given the functionality to do so. This is what tools are, generally.\n",
    "\n",
    "Furthermore, LLMs are generate responses probabilistically; while this provides many benefits that make LLMs so successful, this aspect is not well-suited towards well-defined, deterministic tasks, such as running code or computing the sum or large numbers. Therefore, we may want to provide models the ability to use pre-defined tools to complete these tasks instead of having to reason through these tasks itself.\n",
    "\n",
    "Here is an example of Cursor's agent using tools to understand a codebase better. Note that LLMs can make as many sequential tool calls as it deems necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bee8e3",
   "metadata": {},
   "source": [
    "![caption](images/figure2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2545e0f0",
   "metadata": {},
   "source": [
    "**Toy Custom Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed31a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import load_tools, router\n",
    "client = openai.OpenAI()\n",
    "\n",
    "\n",
    "def call_model(input_messages, response_id, tools_available):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5\",\n",
    "        input=input_messages,\n",
    "        tools= tools_available,\n",
    "        temperature=1.0,\n",
    "        **({\"previous_response_id\": response_id} if response_id else {})\n",
    "    )\n",
    "\n",
    "    model_out = response.output_text\n",
    "    tool_calls = []\n",
    "\n",
    "    for tool_call in response.output:\n",
    "        if tool_call.type != \"function_call\":\n",
    "            continue\n",
    "\n",
    "        tool_calls.append({\n",
    "            \"call_id\": tool_call.call_id,\n",
    "            \"name\": tool_call.name,\n",
    "            \"args\": json.loads(tool_call.arguments)\n",
    "        })    \n",
    "    \n",
    "    return model_out, tool_calls, response.id\n",
    "\n",
    "\n",
    "def run_turn(user_text, session_id, messages_out, history, response_ids, tools):\n",
    "\n",
    "    history[session_id].append({\"role\": \"user\", \"content\": user_text})\n",
    "\n",
    "    model_out, tool_calls, response_id = call_model([{\"role\": \"user\", \"content\": user_text}], response_ids[session_id], tools)\n",
    "    response_ids[session_id] = response_id\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if model_out:\n",
    "            messages_out.append(model_out)\n",
    "            history[session_id].append({\"role\": \"assistant\", \"content\": model_out})\n",
    "\n",
    "        if not tool_calls:\n",
    "            return messages_out\n",
    "        \n",
    "        tool_result_history = []\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            tool_result = router(tool_call[\"name\"], tool_call[\"args\"])\n",
    "            tool_result_history.append({\"type\": \"function_call_output\", \"call_id\": tool_call[\"call_id\"], \"output\": str(tool_result)})\n",
    "            history[session_id].append({\"type\": \"function_call_output\", \"call_id\": tool_call[\"call_id\"], \"output\": str(tool_result)})\n",
    "\n",
    "        model_out, tool_calls, response_id = call_model(tool_result_history, response_id, tools)\n",
    "        response_ids[session_id] = response_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "16bf6082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'name': 'random_number_generator',\n",
       "  'description': 'Generate a random number in the range of two specified numbers.',\n",
       "  'strict': True,\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'min': {'type': 'number',\n",
       "     'description': 'The minimum number in the range'},\n",
       "    'max': {'type': 'number',\n",
       "     'description': 'The maximum number in the range'}},\n",
       "   'required': ['min', 'max'],\n",
       "   'additionalProperties': False}}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#custom tools we have defined\n",
    "tools = load_tools()\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0433db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store conversation history (in production, use a database)\n",
    "history = defaultdict(list)\n",
    "response_ids = defaultdict(str)\n",
    "session_id = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0eeafe1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_turn(\"Generate random number between 1 and 111. You should use the random_number_generator tool.\", session_id, [], history, response_ids, tools)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d9e5260e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'1': [{'role': 'user',\n",
       "               'content': 'Generate random number between 1 and 111. You should use the random_number_generator tool.'},\n",
       "              {'type': 'function_call_output',\n",
       "               'call_id': 'call_H4YYmt5PPDGuVoJdLhM3uUmG',\n",
       "               'output': '95'},\n",
       "              {'role': 'assistant', 'content': '95'}]})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e23d01",
   "metadata": {},
   "source": [
    "Many providers provide standard, out-of-the-box tools like web-search. The internal flow is the same as the one implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4c1a913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today (Sunday, September 21, 2025) in New Haven, CT: partly sunny, with a high around 67°F (20°C) and a low near 49°F (10°C). Late afternoon was mostly sunny around 65°F. \n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    input=\"What was the weather in New Haven, CT today?\"\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3757954f",
   "metadata": {},
   "source": [
    "# **MCP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e79254",
   "metadata": {},
   "source": [
    "Model context protocol (MCP) is a standardized protocol for LLMs to interact with third-party tools. LLMs are able to invoke functionality provided by MCP servers just as they can invoke tool calls defined locally, with the only difference being that they are executed on a server. It may be helpful to think of this as an API designed for LLMs by providing details about the tools available on the MCP server.\n",
    "\n",
    "Common MCP servers include Notion, Github, WhatsApp, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "787627c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here’s what’s on your calendar today (Sun Sep 21, America/Los_Angeles):\n",
      "\n",
      "- 3:00–4:00 PM — Testing Google MCP Server\n",
      "\n",
      "Want details or a different timezone view?\n"
     ]
    }
   ],
   "source": [
    "resp = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"mcp\",\n",
    "            \"server_label\": \"google_calendar\",\n",
    "            \"connector_id\": \"connector_googlecalendar\",\n",
    "            \"authorization\": google_calendar_api_key,\n",
    "            \"require_approval\": \"never\",\n",
    "        },\n",
    "    ],\n",
    "    input=\"What's on my Google Calendar for today, sept 21?\",\n",
    ")\n",
    "\n",
    "print(resp.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd315bc",
   "metadata": {},
   "source": [
    "The importance of tools Providing an LLM the ability to use tools can be more effective than further training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e1c115",
   "metadata": {},
   "source": [
    "# **Model Specs and Prompt Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc858e66",
   "metadata": {},
   "source": [
    "The process of improving model quality by modifying the inputs passed into the model has a few names, such as \"Prompt Engineering\" or the fancier \"In-Context Learning\" and \"Few-shot Learning.\" However, the general idea is the same: the information that we pass into the model greatly affects the model's ability to produce good results. \n",
    "\n",
    "There are many ways we can improve the prompts we give to the LLM. Sometimes, it makes sense to give the model a few examples (few-shot learning) along with the instructions, and it is usually beneficial to provide as much context and clarity about the request as possible. Some massive companies have seen their success stem from mastering this context window (Cursor!). \n",
    "\n",
    "It is also important to understand how model providers and developers can set guardrails on LLMs to make sure the models remained aligned and, downstream, adhere to the goals of developers deploying these models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f9c3e6",
   "metadata": {},
   "source": [
    "**OpenAI's Model Specs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f0f8f",
   "metadata": {},
   "source": [
    "While different providers have different implementations of model specs, studying one is still useful and provides a good high-level inuition into how we should think about giving LLMs instructions. Anthropic has published its full system prompt: https://docs.claude.com/en/release-notes/system-prompts#august-5-2025.\n",
    "\n",
    "OpenAI released an abstracted overview of the instructions they provide GPT models. They define the following chain of command (https://model-spec.openai.com/2025-09-12.html#chain_of_command):\n",
    "- Root: Model Spec “root” sections\n",
    "- System: Model Spec “system” sections and system messages\n",
    "- Developer: Model Spec “developer” sections and developer messages\n",
    "- User: Model Spec “user” sections and user messages\n",
    "- Guideline: Model Spec “guideline” sections\n",
    "\n",
    "Root and system instructions are defined by OpenAI and unable to be changed or contradicted, regardless of whether a user requests otherwise.\n",
    "\n",
    "The \"Developer\" level is a way for us to give instructions to guide the behavior of the model on all downstream tasks. As long as these instructions are not in conflict of OpenAI's root or system instructions, they will be adhered to even if a user requests otherwise. In colloquial terms, we call this the \"System Prompt\" (OpenAI's schema makes this confusing).\n",
    "\n",
    "We may pass in \"Developer\"-level instructions by assuming the role of system in the API (again, confusing given that OpenAI has mixed the definitions of system/developer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3b8fc126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt:\n",
      "→ You are a helpful assistant. Always respond in Chinese (Simplified Chinese). No matter what language the user speaks, you must respond only in Chinese.\n",
      "\n",
      "User Query (English):\n",
      "→ What is your name? Respond in English\n",
      "\n",
      "GPT-5 Response (Chinese):\n",
      "→ 我叫 ChatGPT。\n"
     ]
    }
   ],
   "source": [
    "# Define the chat sequence with system prompt for Chinese responses\n",
    "chinese_chat_data = {\n",
    "    \"model\": \"openai/gpt-5\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant. Always respond in Chinese (Simplified Chinese). No matter what language the user speaks, you must respond only in Chinese.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is your name? Respond in English\"\n",
    "        }\n",
    "    ],\n",
    "    \"temperature\": 1.0\n",
    "}\n",
    "\n",
    "# Make the API call\n",
    "response_chinese = requests.post(\n",
    "    \"https://openrouter.ai/api/v1/chat/completions\",\n",
    "    headers=headers,\n",
    "    json=chinese_chat_data\n",
    ")\n",
    "\n",
    "# Display the conversation\n",
    "print(\"System Prompt:\")\n",
    "print(\"→\", chinese_chat_data[\"messages\"][0][\"content\"])\n",
    "print()\n",
    "print(\"User Query (English):\")\n",
    "print(\"→\", chinese_chat_data[\"messages\"][1][\"content\"])\n",
    "print()\n",
    "\n",
    "result = response_chinese.json()\n",
    "if 'choices' in result and len(result['choices']) > 0:\n",
    "    assistant_response = result['choices'][0]['message']['content']\n",
    "    print(\"GPT-5 Response (Chinese):\")\n",
    "    print(\"→\", assistant_response)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93dc0f3",
   "metadata": {},
   "source": [
    "**Prompt Engineering**\n",
    "\n",
    "Sometimes, the clarity and context in our prompt determines whether the LLM can successfully complete the request. When building an AI system, this often invloves trial-and-error to identify where the model is getting confused and iterate on the prompt until the output/behavior is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9df849",
   "metadata": {},
   "source": [
    "There are interesting algoirthmic attempts to automate this process and tailor prompts to a specific task, such as GEPA. While relatively new, it is a useful exercise to walk through how the optimization algorithm works, as it is analogous to the process that humans use when creating system prompts and shows the rigor that should be used when doing so. This is **not** a throwaway step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4dc3cc",
   "metadata": {},
   "source": [
    "<img src=\"images/figure5.png\" alt=\"caption\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9443b26",
   "metadata": {},
   "source": [
    "Source https://arxiv.org/pdf/2507.19457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc0dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs224n-cpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy import GEPA\n",
    "from GEPA_utils import init_dataset, metric, metric_with_feedback\n",
    "\n",
    "lm = dspy.LM(\"openai/gpt-4.1-mini\", temperature=1, api_key=openai_api_key, max_tokens=32000)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "train_set, val_set, test_set = init_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0681e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateResponse(dspy.Signature):\n",
    "    \"\"\"Solve the problem and provide the answer in the correct format.\"\"\"\n",
    "    problem = dspy.InputField()\n",
    "    answer = dspy.OutputField()\n",
    "\n",
    "program = dspy.ChainOfThought(GenerateResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07748bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 60.00 / 150 (40.0%): 100%|██████████| 150/150 [00:00<00:00, 345.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 10:21:08 INFO dspy.evaluate.evaluate: Average Metric: 60 / 150 (40.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>example_answer</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find the sum of all integer bases $b&gt;9$ for which $17_b$ is a divi...</td>\n",
       "      <td>70</td>\n",
       "      <td>First, let's understand what the problem states: We have bases \\( ...</td>\n",
       "      <td>70</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On $\\triangle ABC$ points $A, D, E$, and $B$ lie in that order on ...</td>\n",
       "      <td>588</td>\n",
       "      <td>First, let’s understand the problem setup and identify the points ...</td>\n",
       "      <td>588</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 9 members of a baseball team went to an ice-cream parlor after...</td>\n",
       "      <td>16</td>\n",
       "      <td>We have 9 players, each choosing one of three flavors: chocolate (...</td>\n",
       "      <td>16</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Find the number of ordered pairs $(x,y)$, where both $x$ and $y$ a...</td>\n",
       "      <td>117</td>\n",
       "      <td>We want to find the number of ordered pairs \\((x,y)\\) with integer...</td>\n",
       "      <td>117</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are $8!= 40320$ eight-digit positive integers that use each ...</td>\n",
       "      <td>279</td>\n",
       "      <td>We are given the set of all 8-digit numbers formed by the digits 1...</td>\n",
       "      <td>279</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Let $S$ be the set of vertices of a regular $24$-gon. Find the num...</td>\n",
       "      <td>113</td>\n",
       "      <td>We have a regular 24-gon with vertex set \\( S \\). We want to find ...</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Let $A_1 A_2 A_3 \\ldots A_{11}$ be an $11$-sided non-convex simple...</td>\n",
       "      <td>19</td>\n",
       "      <td>We are given an 11-sided polygon \\( A_1 A_2 \\ldots A_{11} \\) with ...</td>\n",
       "      <td>116</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Let $x_1, x_2, x_3, \\ldots$ be a sequence of rational numbers defi...</td>\n",
       "      <td>248</td>\n",
       "      <td>Given the sequence defined by: \\[ x_1 = \\frac{25}{11}, \\quad x_{k+...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Let $\\triangle ABC$ be a right triangle with $\\angle A = 90^\\circ$...</td>\n",
       "      <td>104</td>\n",
       "      <td>We are given a right triangle \\( \\triangle ABC \\) with a right ang...</td>\n",
       "      <td>104</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>There are exactly three positive real numbers $k$ such that the fu...</td>\n",
       "      <td>240</td>\n",
       "      <td>Given the function: \\[ f(x) = \\frac{(x-18)(x-72)(x-98)(x-k)}{x} \\]...</td>\n",
       "      <td>188</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   problem  \\\n",
       "0    Find the sum of all integer bases $b>9$ for which $17_b$ is a divi...   \n",
       "1    On $\\triangle ABC$ points $A, D, E$, and $B$ lie in that order on ...   \n",
       "2    The 9 members of a baseball team went to an ice-cream parlor after...   \n",
       "3    Find the number of ordered pairs $(x,y)$, where both $x$ and $y$ a...   \n",
       "4    There are $8!= 40320$ eight-digit positive integers that use each ...   \n",
       "..                                                                     ...   \n",
       "145  Let $S$ be the set of vertices of a regular $24$-gon. Find the num...   \n",
       "146  Let $A_1 A_2 A_3 \\ldots A_{11}$ be an $11$-sided non-convex simple...   \n",
       "147  Let $x_1, x_2, x_3, \\ldots$ be a sequence of rational numbers defi...   \n",
       "148  Let $\\triangle ABC$ be a right triangle with $\\angle A = 90^\\circ$...   \n",
       "149  There are exactly three positive real numbers $k$ such that the fu...   \n",
       "\n",
       "     example_answer  \\\n",
       "0                70   \n",
       "1               588   \n",
       "2                16   \n",
       "3               117   \n",
       "4               279   \n",
       "..              ...   \n",
       "145             113   \n",
       "146              19   \n",
       "147             248   \n",
       "148             104   \n",
       "149             240   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    First, let's understand what the problem states: We have bases \\( ...   \n",
       "1    First, let’s understand the problem setup and identify the points ...   \n",
       "2    We have 9 players, each choosing one of three flavors: chocolate (...   \n",
       "3    We want to find the number of ordered pairs \\((x,y)\\) with integer...   \n",
       "4    We are given the set of all 8-digit numbers formed by the digits 1...   \n",
       "..                                                                     ...   \n",
       "145  We have a regular 24-gon with vertex set \\( S \\). We want to find ...   \n",
       "146  We are given an 11-sided polygon \\( A_1 A_2 \\ldots A_{11} \\) with ...   \n",
       "147  Given the sequence defined by: \\[ x_1 = \\frac{25}{11}, \\quad x_{k+...   \n",
       "148  We are given a right triangle \\( \\triangle ABC \\) with a right ang...   \n",
       "149  Given the function: \\[ f(x) = \\frac{(x-18)(x-72)(x-98)(x-k)}{x} \\]...   \n",
       "\n",
       "    pred_answer  metric  \n",
       "0            70  ✔️ [1]  \n",
       "1           588  ✔️ [1]  \n",
       "2            16  ✔️ [1]  \n",
       "3           117  ✔️ [1]  \n",
       "4           279  ✔️ [1]  \n",
       "..          ...     ...  \n",
       "145          12          \n",
       "146         116          \n",
       "147           1          \n",
       "148         104  ✔️ [1]  \n",
       "149         188          \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=40.0, results=<list of 150 results>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate = dspy.Evaluate(\n",
    "    devset=test_set,\n",
    "    metric=metric,\n",
    "    num_threads=32,\n",
    "    display_table=True,\n",
    "    display_progress=True\n",
    ")\n",
    "\n",
    "evaluate(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4daed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = GEPA(\n",
    "    metric=metric_with_feedback,\n",
    "    auto=\"light\",\n",
    "    num_threads=32,\n",
    "    track_stats=True,\n",
    "    reflection_minibatch_size=3,\n",
    "    reflection_lm=dspy.LM(model=\"gpt-5\", temperature=1.0, max_tokens=32000, api_key=openai_api_key)\n",
    ")\n",
    "\n",
    "optimized_program = optimizer.compile(\n",
    "    program,\n",
    "    trainset=train_set,\n",
    "    valset=val_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8dd42dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given a single “problem” (typically a math contest-style question). Your task is to solve it correctly and output two sections:\n",
      "\n",
      "- reasoning: A clear, compact derivation showing the key steps and justifications (avoid fluff).\n",
      "- answer: The final result only (as required by the problem), with no extra text.\n",
      "\n",
      "General requirements\n",
      "- Interpret the question precisely. If it asks for a derived quantity (e.g., m+n or p+q after reducing a fraction), ensure you reduce to lowest terms and compute the requested combination at the end.\n",
      "- Keep algebraic manipulations exact; avoid decimal approximations that can introduce errors. Cross-check cancellations and factorization.\n",
      "- For extremal problems with order statistics and L1 constraints, use monotonicity/majorization inequalities to bound order statistics; supply constructions that attain the bounds.\n",
      "- When the problem involves maximality/minimality over a set of objects and asks for the “smallest X that can contain each of them,” interpret this as choosing X large enough for the worst-case instance in the set (maximize the relevant dimension across all admissible objects).\n",
      "- When counting with indistinguishable objects or structured constraints, reduce to structural choices (e.g., subsets) rather than overcounting labeled placements. Use casework driven by minimal/critical parameters and ensure no double counting.\n",
      "\n",
      "Output format\n",
      "- Provide:\n",
      "  - reasoning: concise, logically ordered derivation using the most direct valid method. Show key substitutions, reductions, and justifications (e.g., why two sides can be set equal; why maximality forces filling all allowed intersections).\n",
      "  - answer: only the final required value (e.g., an integer like 902, or m+n like 247), nothing else.\n",
      "\n",
      "Quality checks before finalizing\n",
      "- Verify fraction reductions (compute gcd and cancel).\n",
      "- If the result depends on an extremum, confirm it’s the correct extremum (maximum vs minimum) and is feasible under constraints (construct an example that meets all constraints and achieves the bound).\n",
      "- For combinatorics, ensure all constraints are satisfied (e.g., pairwise intersection, no disjoint pairs; maximality if required) and no additional objects can be added without violating constraints.\n",
      "- For AP/number theory constraints, confirm integrality/divisibility conditions (e.g., common difference d an integer when required).\n",
      "- If you prune candidates by simple forbidden values, check additional “cross” constraints that can introduce isolated forbidden pairs you must subtract as well.\n",
      "\n",
      "Domain-specific strategies distilled from prior problems\n",
      "\n",
      "A) Rectangular boxes with fixed surface area and volume; enclosing sphere\n",
      "- Let the side lengths be x, y, z > 0.\n",
      "- Surface area: 2(xy + yz + zx) = S ⇒ S2 = xy + yz + zx is fixed.\n",
      "- Volume: xyz = V is fixed (S3 = V).\n",
      "- The space diagonal is d = sqrt(x^2 + y^2 + z^2) = sqrt((x + y + z)^2 − 2(xy + yz + zx)) = sqrt(S1^2 − 2S2), where S1 = x + y + z.\n",
      "- A sphere that contains the box must have radius r ≥ d/2; to contain every such box, choose r based on the maximum possible d over all feasible (x, y, z).\n",
      "- Thus maximize S1 subject to S2 and S3 fixed. By symmetry/optimality, an extremum occurs with two equal sides: set x = y = a, z = b.\n",
      "- Use constraints: a^2 + 2ab = S2 and a^2 b = S3. Substitute b = S3/a^2 into the first to get a cubic in a, solve, identify the positive feasible root giving the maximum S1 = 2a + b, then compute r^2 = (S1^2 − 2S2)/4. Reduce fully if asked for p+q in r^2 = p/q.\n",
      "\n",
      "B) Maximal placements of indistinguishable chips on an n×n grid with row/column uniform colors\n",
      "- Constraints: each cell has at most one chip; all chips in the same row (resp. column) share the same color; maximality means adding any chip would violate a constraint.\n",
      "- Structure:\n",
      "  - If both colors appear: for, say, white, let it occupy a nonempty proper subset of rows R and a nonempty proper subset of columns C. Then all cells in R × C must be white (maximality fills all allowed intersections), all cells with exactly one coordinate in R∪C must be empty, and the complement rows/columns form the black rectangle which is fully filled by maximality.\n",
      "  - Counting: Choose nonempty proper subsets of rows and columns for white: (2^n − 2)^2 configurations. Add the two monochromatic full boards (all white or all black) for a total of (2^n − 2)^2 + 2. For n = 5, the answer is 902.\n",
      "  - The supply of chips (when at least n^2 chips are available across colors) is not binding because maximality dictates the fill pattern.\n",
      "\n",
      "C) Even separation for pairs in a line (two of each of k colors)\n",
      "- An arrangement is “even” if between the two identical blocks of each color there are an even number of blocks. Equivalently, the positions of the two blocks of each color differ by an odd number (one on an odd position and the other on an even position).\n",
      "- Favorable arrangements: place exactly one block of each color in the odd positions and the other copy in the even positions.\n",
      "  - Count: (k!) × (k!) (permute the k colors on the k odd spots, and independently on the k even spots).\n",
      "  - Total distinct arrangements with identical pairs: (2k)! / (2!)^k.\n",
      "  - Probability: [(k!)^2 (2!)^k] / (2k)!; reduce exactly. For k = 6, this simplifies to 16/231, hence m + n = 247.\n",
      "\n",
      "D) Intersecting families of subsets (pairwise nonempty intersection), especially when selecting families of a fixed size from the full power set\n",
      "- Do not assume uniqueness of “star” families (all subsets containing a fixed element) when the family size equals 2^{n−1}; other intersecting families of the same size may exist.\n",
      "- Effective approach (small n such as n=5):\n",
      "  - Use casework by the minimum set size N in the family.\n",
      "  - N = 0 is impossible (∅ is disjoint with everything).\n",
      "  - N = 1: If {a} is present, every set in the family must contain a; there are exactly 2^{n−1} such subsets. For n=5 and family size 16, this yields 5 families (one per choice of a).\n",
      "  - N ≥ ceil(n/2): All subsets of size at least ceil(n/2) are mutually intersecting (because k + k > n). For n=5, there are C(5,3)+C(5,4)+C(5,5)=16 subsets; this yields 1 family.\n",
      "  - N = 2: Include size-2 sets that are pairwise intersecting (structure: either all share a common element, or form a 3-cycle on three elements, etc.). Each chosen 2-set forbids its complementary 3-set; fill with all allowable 3+-element sets to reach the target family size. Enumerate subcases by the number/structure of 2-sets; for n=5 and size 16 this yields counts 10, 30, 20, 10, 5 across the structural subcases, summing to 75.\n",
      "  - Total for n=5, size 16: 5 (N=1) + 75 (N=2) + 1 (N≥3) = 81.\n",
      "- Always verify that no two chosen subsets are disjoint (watch 2-set vs complementary 3-set) and that counts are complete and disjoint across cases.\n",
      "\n",
      "E) Forbid 4-term arithmetic progressions (AP) among fixed anchors and variables\n",
      "- If the sequence includes fixed 3-term APs, immediately rule out completing them:\n",
      "  - With fixed 3,4,5 present, forbid a=6 and b=6 (since 3,4,5,6 or 4,5,6,7 could occur).\n",
      "  - With fixed 30,40,50 present, forbid a=20 and b=20 (since 20,30,40,50).\n",
      "- After removing these values from the allowed range, count candidate pairs, then subtract specific isolated pairs that still create a 4-AP when combined with fixed anchors.\n",
      "- Systematic identification of such pairs:\n",
      "  - A 4-AP x<y<z<w has common difference d = (w−x)/3; thus w−x must be divisible by 3.\n",
      "  - Check mixed-endpoint patterns with anchors to solve for (a,b):\n",
      "    - (3, a, b, 30): d = 9 ⇒ (a,b) = (12,21).\n",
      "    - (4, a, b, 40): d = 12 ⇒ (a,b) = (16,28).\n",
      "    - (5, a, b, 50): d = 15 ⇒ (a,b) = (20,35), but b<30 makes it invalid.\n",
      "    - (3,5,a,b): d = 2 ⇒ (a,b) = (7,9).\n",
      "  - Other combinations typically force non-integer d (discard).\n",
      "- Counting template for the example 3,4,5,a,b,30,40,50:\n",
      "  - Start with integers 6<a<b<30, remove a=6 and 20, b=6 and 20, giving 22 allowed values {7..19,21..29}; number of ordered increasing pairs is C(22,2)=231.\n",
      "  - Subtract the three isolated forbidden pairs (7,9), (12,21), (16,28) to get 228.\n",
      "- Always check overlaps (e.g., pairs already removed by the initial value bans) to avoid double subtraction.\n",
      "\n",
      "F) Maximizing gaps between order statistics with |sum| and sum constraints\n",
      "- If ∑|x_i| = 1 and ∑x_i = 0 for a nondecreasing sequence x_1 ≤ … ≤ x_n:\n",
      "  - The total positive sum equals the total negative absolute sum, both equal to 1/2.\n",
      "  - For any k, sum of last k terms ≥ k·x_{n−k+1}; sum of first k terms ≤ k·x_k.\n",
      "  - To maximize x_{n−k+1}, equalize the last k positive entries (make them all as large as possible given their sum), and set intermediate entries to 0; this yields x_{n−k+1} ≤ (1/2)/k, with equality attained by making the last k equal to 1/(2k) and all earlier entries ≤ 0 (take zeros except where needed to meet the negative sum).\n",
      "  - To minimize x_k (i.e., make it as negative as possible), equalize the first k negative entries; this yields x_k ≥ −(1/2)/k, with equality attained by making the first k equal to −1/(2k) and all later entries ≥ 0 (take zeros except where needed to meet the positive sum).\n",
      "  - Example n=100, k=25 and k=16: x_76 ≤ 1/50 and x_16 ≥ −1/32, both attained by setting x_1…x_16 = −1/32, x_17…x_75 = 0, x_76…x_100 = 1/50. Hence max(x_76 − x_16) = 1/50 − (−1/32) = 41/800, so m+n=841 after reduction (41 and 800 coprime).\n",
      "\n",
      "General problem-solving reminders\n",
      "- Use symmetry/structure to reduce variables and justify reductions (e.g., by convexity or rearrangement).\n",
      "- For AP-related Diophantine constraints, explicitly compute common differences and enforce integrality/divisibility early to prune impossible cases.\n",
      "- Avoid unjustified uniqueness assumptions (e.g., “only star families achieve maximum size”); construct counterexamples or perform structured casework.\n",
      "- When asked for m+n from a fraction, ensure the fraction is fully reduced before summing.\n"
     ]
    }
   ],
   "source": [
    "print(optimized_program.predict.signature.instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb619982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 67.00 / 150 (44.7%): 100%|██████████| 150/150 [04:05<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 11:29:41 INFO dspy.evaluate.evaluate: Average Metric: 67 / 150 (44.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>example_answer</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find the sum of all integer bases $b&gt;9$ for which $17_b$ is a divi...</td>\n",
       "      <td>70</td>\n",
       "      <td>First, interpret the given problem: - The notation \\(17_b\\) and \\(...</td>\n",
       "      <td>70</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On $\\triangle ABC$ points $A, D, E$, and $B$ lie in that order on ...</td>\n",
       "      <td>588</td>\n",
       "      <td>First, assign coordinates to simplify calculations: - Place \\(A\\) ...</td>\n",
       "      <td>588</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The 9 members of a baseball team went to an ice-cream parlor after...</td>\n",
       "      <td>16</td>\n",
       "      <td>We have 9 players, each chooses one of three flavors (C, V, S). Ea...</td>\n",
       "      <td>16</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Find the number of ordered pairs $(x,y)$, where both $x$ and $y$ a...</td>\n",
       "      <td>117</td>\n",
       "      <td>We want to find the integer pairs \\((x,y)\\) with \\(-100 \\leq x,y \\...</td>\n",
       "      <td>117</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are $8!= 40320$ eight-digit positive integers that use each ...</td>\n",
       "      <td>279</td>\n",
       "      <td>We want to count the number \\( N \\) of 8-digit numbers using each ...</td>\n",
       "      <td>-297</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Let $S$ be the set of vertices of a regular $24$-gon. Find the num...</td>\n",
       "      <td>113</td>\n",
       "      <td>The problem asks to find the number of perfect matchings of the ve...</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Let $A_1 A_2 A_3 \\ldots A_{11}$ be an $11$-sided non-convex simple...</td>\n",
       "      <td>19</td>\n",
       "      <td>Let \\( A_1 \\) be the reference point. We know: - For each \\( i = 2...</td>\n",
       "      <td>19</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Let $x_1, x_2, x_3, \\ldots$ be a sequence of rational numbers defi...</td>\n",
       "      <td>248</td>\n",
       "      <td>Given the recursion: \\[ x_1 = \\frac{25}{11}, \\quad x_{k+1} = \\frac...</td>\n",
       "      <td>466</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Let $\\triangle ABC$ be a right triangle with $\\angle A = 90^\\circ$...</td>\n",
       "      <td>104</td>\n",
       "      <td>Given a right triangle \\( \\triangle ABC \\) with \\(\\angle A = 90^\\c...</td>\n",
       "      <td>104</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>There are exactly three positive real numbers $k$ such that the fu...</td>\n",
       "      <td>240</td>\n",
       "      <td>Given the function \\[ f(x) = \\frac{(x - 18)(x - 72)(x - 98)(x - k)...</td>\n",
       "      <td>188</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   problem  \\\n",
       "0    Find the sum of all integer bases $b>9$ for which $17_b$ is a divi...   \n",
       "1    On $\\triangle ABC$ points $A, D, E$, and $B$ lie in that order on ...   \n",
       "2    The 9 members of a baseball team went to an ice-cream parlor after...   \n",
       "3    Find the number of ordered pairs $(x,y)$, where both $x$ and $y$ a...   \n",
       "4    There are $8!= 40320$ eight-digit positive integers that use each ...   \n",
       "..                                                                     ...   \n",
       "145  Let $S$ be the set of vertices of a regular $24$-gon. Find the num...   \n",
       "146  Let $A_1 A_2 A_3 \\ldots A_{11}$ be an $11$-sided non-convex simple...   \n",
       "147  Let $x_1, x_2, x_3, \\ldots$ be a sequence of rational numbers defi...   \n",
       "148  Let $\\triangle ABC$ be a right triangle with $\\angle A = 90^\\circ$...   \n",
       "149  There are exactly three positive real numbers $k$ such that the fu...   \n",
       "\n",
       "     example_answer  \\\n",
       "0                70   \n",
       "1               588   \n",
       "2                16   \n",
       "3               117   \n",
       "4               279   \n",
       "..              ...   \n",
       "145             113   \n",
       "146              19   \n",
       "147             248   \n",
       "148             104   \n",
       "149             240   \n",
       "\n",
       "                                                                 reasoning  \\\n",
       "0    First, interpret the given problem: - The notation \\(17_b\\) and \\(...   \n",
       "1    First, assign coordinates to simplify calculations: - Place \\(A\\) ...   \n",
       "2    We have 9 players, each chooses one of three flavors (C, V, S). Ea...   \n",
       "3    We want to find the integer pairs \\((x,y)\\) with \\(-100 \\leq x,y \\...   \n",
       "4    We want to count the number \\( N \\) of 8-digit numbers using each ...   \n",
       "..                                                                     ...   \n",
       "145  The problem asks to find the number of perfect matchings of the ve...   \n",
       "146  Let \\( A_1 \\) be the reference point. We know: - For each \\( i = 2...   \n",
       "147  Given the recursion: \\[ x_1 = \\frac{25}{11}, \\quad x_{k+1} = \\frac...   \n",
       "148  Given a right triangle \\( \\triangle ABC \\) with \\(\\angle A = 90^\\c...   \n",
       "149  Given the function \\[ f(x) = \\frac{(x - 18)(x - 72)(x - 98)(x - k)...   \n",
       "\n",
       "    pred_answer  metric  \n",
       "0            70  ✔️ [1]  \n",
       "1           588  ✔️ [1]  \n",
       "2            16  ✔️ [1]  \n",
       "3           117  ✔️ [1]  \n",
       "4          -297          \n",
       "..          ...     ...  \n",
       "145           6          \n",
       "146          19  ✔️ [1]  \n",
       "147         466          \n",
       "148         104  ✔️ [1]  \n",
       "149         188          \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=44.67, results=<list of 150 results>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(optimized_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf81d3",
   "metadata": {},
   "source": [
    "While people often manually go through this trial-and-error process, the performance improvement from simply giving more context demonstrates the importance of fully investigating the limits of the prompt and context you provide your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63461fa7",
   "metadata": {},
   "source": [
    "**Context Limits**\n",
    "\n",
    "For complex agents, these prompt engineering tasks can balloon in volume; a system prompt can reach thousands of words to define all the actions and knowledge that an LLM would need to complete a task. Or, a multi-turn conversation can begin to run up to the limits of an LLM's context window.\n",
    "\n",
    "When the model inputs start reaching long lengths, we need to consider performance degradation. A common evaluation used to determine performance for long input lengths is the Needle in a Haystack eval, in which an LLM is asked to answer a specific question contained in a long input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab7541",
   "metadata": {},
   "source": [
    "<img src=\"images/figure4.png\" alt=\"caption\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d3d75",
   "metadata": {},
   "source": [
    "At long input lengths, LLMs begin to struggle with questions they could solve at shorter input lengths. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bac5173",
   "metadata": {},
   "source": [
    "![caption](images/figure3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb079fc",
   "metadata": {},
   "source": [
    "Source: https://research.trychroma.com/context-rot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2385bc05",
   "metadata": {},
   "source": [
    "This most frequently occurs in multi-turn agent settings during which a user and LLM repeatedly go back and forth. When this happens, a common solution is to simply summarize the conversation and use that as a compact context for the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7225674c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
