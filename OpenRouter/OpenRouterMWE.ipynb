{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71965253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, dotenv\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [dotenv]\n",
      "\u001b[1A\u001b[2KSuccessfully installed dotenv-0.9.9 python-dotenv-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ad9f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import dotenv\n",
    "from utils import get_price\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190f85c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.getenv('OPENROUTER_API')}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "chat_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "models_url = \"https://openrouter.ai/api/v1/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ae28ee",
   "metadata": {},
   "source": [
    "**Get Available Models**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cebc634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA Nemotron Nano 9B V2 model info:\n",
      "\"nvidia/nemotron-nano-9b-v2\"\n",
      "\"NVIDIA-Nemotron-Nano-9B-v2 is a large language model (LLM) trained from scratch by NVIDIA, and designed as a unified model for both reasoning and non-reasoning tasks. It responds to user queries and tasks by first generating a reasoning trace and then concluding with a final response. \\n\\nThe model's reasoning capabilities can be controlled via a system prompt. If the user prefers the model to provide its final answer without intermediate reasoning traces, it can be configured to do so.\"\n",
      "{\n",
      "  \"modality\": \"text->text\",\n",
      "  \"input_modalities\": [\n",
      "    \"text\"\n",
      "  ],\n",
      "  \"output_modalities\": [\n",
      "    \"text\"\n",
      "  ],\n",
      "  \"tokenizer\": \"Other\",\n",
      "  \"instruct_type\": null\n",
      "}\n",
      "{\n",
      "  \"prompt\": \"0\",\n",
      "  \"completion\": \"0\",\n",
      "  \"request\": \"0\",\n",
      "  \"image\": \"0\",\n",
      "  \"web_search\": \"0\",\n",
      "  \"internal_reasoning\": \"0\"\n",
      "}\n",
      "{\n",
      "  \"context_length\": 128000,\n",
      "  \"max_completion_tokens\": null,\n",
      "  \"is_moderated\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(models_url)\n",
    "\n",
    "with open(\"models_response.json\", \"w\") as f:\n",
    "    json.dump(response.json(), f, indent=2)\n",
    "\n",
    "    models_data = response.json()\n",
    "    nemotron_info = None\n",
    "    for model in models_data.get(\"data\", []):\n",
    "        if model.get(\"id\") == \"nvidia/nemotron-nano-9b-v2\":\n",
    "            nemotron_info = model\n",
    "            print(\"NVIDIA Nemotron Nano 9B V2 model info:\")\n",
    "            print(json.dumps(nemotron_info.get(\"id\"), indent=2))\n",
    "            print(json.dumps(nemotron_info.get(\"description\"), indent=2))\n",
    "            print(json.dumps(nemotron_info.get(\"architecture\"), indent=2))\n",
    "            print(json.dumps(nemotron_info.get(\"pricing\"), indent=2))\n",
    "            print(json.dumps(nemotron_info.get(\"top_provider\"), indent=2))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daccab24",
   "metadata": {},
   "source": [
    "**Minimal Implementation of Completions API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806ffb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is to find purpose, connection, and fulfillment through personal growth, relationships, and contributing to something greater than oneself.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(chat_url,headers=headers, json={\n",
    "    \"model\": \"nvidia/nemotron-nano-9b-v2\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the meaning of life? Answer in one sentence.\"\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "print(response.json().get(\"choices\")[0].get(\"message\").get(\"content\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293e5853",
   "metadata": {},
   "source": [
    "**Taking Advantage of Openrouter's Routing**: \n",
    "\n",
    "\n",
    "With OpenRouter, we can optimize for multiple objectives in routing to a model and provider, such as cost, latency, etc.\n",
    "\n",
    "We can also specify backup models to control for model downtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5501ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#find best (cheapest) provider for fixed model\n",
    "response = requests.post(chat_url, headers=headers, json={\n",
    "    #\n",
    "    'models': ['meta-llama/llama-3.1-70b-instruct', 'nvidia/nemotron-nano-9b-v2'],\n",
    "    'messages': [\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': 'What is the meaning of life? Answer in 5 words.'\n",
    "      }\n",
    "    ],\n",
    "\n",
    "    #tell openrouter to sort by price, other options are \"throughput\" and \"latency\"\n",
    "    #also tell openrouter to deny data collection\n",
    "    'provider': {\n",
    "      'sort': 'price',\n",
    "      'data_collection': 'deny'\n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f54a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routed to: DeepInfra\n",
      "Model: meta-llama/llama-3.1-70b-instruct\n",
      "Response: To find your own purpose.\n",
      "Price: $0.00000398\n"
     ]
    }
   ],
   "source": [
    "print(f\"Routed to: {response.json().get('provider')}\")\n",
    "print(f\"Model: {response.json().get('model')}\")\n",
    "print(f\"Response: {response.json().get('choices')[0].get('message').get('content')}\")\n",
    "print(\"Price:\", get_price(response))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cf158b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4afeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
