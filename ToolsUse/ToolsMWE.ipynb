{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b43e1174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.107.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/cs224n-cpu/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/cs224n-cpu/lib/python3.10/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/cs224n-cpu/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/cs224n-cpu/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/cs224n-cpu/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-1.107.0-py3-none-any.whl (950 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.0/951.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-macosx_11_0_arm64.whl (322 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/12\u001b[0m [openai]11/12\u001b[0m [openai]c]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.10.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.107.0 pydantic-2.11.7 pydantic-core-2.33.2 sniffio-1.3.1 typing-inspection-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c52c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tools import load_tools, router\n",
    "from collections import defaultdict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb840889",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621150ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(input_messages, response_id):\n",
    "    print(\"interior call model, \", response_id)\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5-mini\",\n",
    "        input=input_messages,\n",
    "        **({\"tools\": tools} if response_id else {}),\n",
    "        **({\"previous_response_id\": response_id} if response_id else {})\n",
    "    )\n",
    "\n",
    "    model_out = response.output_text\n",
    "    tool_calls = []\n",
    "\n",
    "    for tool_call in response.output:\n",
    "        if tool_call.type != \"function_call\":\n",
    "            continue\n",
    "\n",
    "        tool_calls.append({\n",
    "            \"call_id\": tool_call.call_id,\n",
    "            \"name\": tool_call.name,\n",
    "            \"args\": json.loads(tool_call.arguments)\n",
    "        })    \n",
    "    \n",
    "    return model_out, tool_calls, response.id\n",
    "\n",
    "\n",
    "def run_turn(user_text, session_id, messages_out):\n",
    "\n",
    "    history[session_id].append({\"role\": \"user\", \"content\": user_text})\n",
    "    print(response_ids[session_id])\n",
    "\n",
    "    model_out, tool_calls, response_id = call_model([{\"role\": \"user\", \"content\": user_text}], response_ids[session_id])\n",
    "    response_ids[session_id] = response_id\n",
    "\n",
    "    while True:\n",
    "\n",
    "        if model_out:\n",
    "            messages_out.append(model_out)\n",
    "            history[session_id].append({\"role\": \"assistant\", \"content\": model_out})\n",
    "\n",
    "        if not tool_calls:\n",
    "            return messages_out\n",
    "        \n",
    "        print(\"sending tool calls\")\n",
    "\n",
    "        tool_result_history = []\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            tool_result = router(tool_call[\"name\"], tool_call[\"args\"])\n",
    "            tool_result_history.append({\"type\": \"function_call_output\", \"call_id\": tool_call[\"call_id\"], \"output\": str(tool_result)})\n",
    "            history[session_id].append({\"type\": \"function_call_output\", \"call_id\": tool_call[\"call_id\"], \"output\": str(tool_result)})\n",
    "\n",
    "        print(\"sending tool result history\")\n",
    "        model_out, tool_calls, response_id = call_model(tool_result_history, response_id)\n",
    "        response_ids[session_id] = response_id\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
